{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2b9cb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbe99109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63,)\n",
      "(43135,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df\n",
    "print(x_train[0].shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3fd766b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43135, 65)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Datasets//balanced_dataset - balanced_dataset.csv\",sep=',',header=None)\n",
    "\n",
    "print(df.values.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc3495eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df.values[1:41474,64]\n",
    "x_train = df.values[1:41474,1:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a9d211cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41473, 63)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0349484a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.709993</td>\n",
       "      <td>0.782589</td>\n",
       "      <td>0</td>\n",
       "      <td>0.818884</td>\n",
       "      <td>0.729557</td>\n",
       "      <td>-0.056234</td>\n",
       "      <td>0.896666</td>\n",
       "      <td>0.582237</td>\n",
       "      <td>-0.075635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587765</td>\n",
       "      <td>0.510154</td>\n",
       "      <td>-0.120703</td>\n",
       "      <td>0.614871</td>\n",
       "      <td>0.600813</td>\n",
       "      <td>-0.114690</td>\n",
       "      <td>0.633652</td>\n",
       "      <td>0.669997</td>\n",
       "      <td>-0.091255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.338549</td>\n",
       "      <td>0.505901</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439657</td>\n",
       "      <td>0.437370</td>\n",
       "      <td>-0.020094</td>\n",
       "      <td>0.506951</td>\n",
       "      <td>0.327512</td>\n",
       "      <td>-0.032897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241660</td>\n",
       "      <td>0.278901</td>\n",
       "      <td>-0.113734</td>\n",
       "      <td>0.265261</td>\n",
       "      <td>0.351731</td>\n",
       "      <td>-0.101954</td>\n",
       "      <td>0.284056</td>\n",
       "      <td>0.413315</td>\n",
       "      <td>-0.081208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.331600</td>\n",
       "      <td>0.650407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.440002</td>\n",
       "      <td>0.610693</td>\n",
       "      <td>-0.018637</td>\n",
       "      <td>0.524808</td>\n",
       "      <td>0.536133</td>\n",
       "      <td>-0.029701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285742</td>\n",
       "      <td>0.432299</td>\n",
       "      <td>-0.111022</td>\n",
       "      <td>0.290253</td>\n",
       "      <td>0.490377</td>\n",
       "      <td>-0.097487</td>\n",
       "      <td>0.295378</td>\n",
       "      <td>0.546413</td>\n",
       "      <td>-0.078214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.763677</td>\n",
       "      <td>0.944873</td>\n",
       "      <td>0</td>\n",
       "      <td>0.855445</td>\n",
       "      <td>0.899674</td>\n",
       "      <td>-0.023865</td>\n",
       "      <td>0.913678</td>\n",
       "      <td>0.815270</td>\n",
       "      <td>-0.036524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.706913</td>\n",
       "      <td>0.725790</td>\n",
       "      <td>-0.079980</td>\n",
       "      <td>0.723299</td>\n",
       "      <td>0.791177</td>\n",
       "      <td>-0.070449</td>\n",
       "      <td>0.724961</td>\n",
       "      <td>0.845564</td>\n",
       "      <td>-0.056686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43130</th>\n",
       "      <td>43129.0</td>\n",
       "      <td>0.618995</td>\n",
       "      <td>0.709756</td>\n",
       "      <td>0</td>\n",
       "      <td>0.714638</td>\n",
       "      <td>0.767420</td>\n",
       "      <td>-0.089490</td>\n",
       "      <td>0.863142</td>\n",
       "      <td>0.729784</td>\n",
       "      <td>-0.122185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768363</td>\n",
       "      <td>0.460456</td>\n",
       "      <td>-0.096203</td>\n",
       "      <td>0.716564</td>\n",
       "      <td>0.536624</td>\n",
       "      <td>-0.100405</td>\n",
       "      <td>0.681609</td>\n",
       "      <td>0.597335</td>\n",
       "      <td>-0.085523</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43131</th>\n",
       "      <td>43130.0</td>\n",
       "      <td>0.380424</td>\n",
       "      <td>0.777277</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499145</td>\n",
       "      <td>0.807409</td>\n",
       "      <td>-0.031173</td>\n",
       "      <td>0.633429</td>\n",
       "      <td>0.749210</td>\n",
       "      <td>-0.050144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472842</td>\n",
       "      <td>0.503088</td>\n",
       "      <td>-0.120579</td>\n",
       "      <td>0.472228</td>\n",
       "      <td>0.587706</td>\n",
       "      <td>-0.111767</td>\n",
       "      <td>0.454988</td>\n",
       "      <td>0.660927</td>\n",
       "      <td>-0.095761</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43132</th>\n",
       "      <td>43131.0</td>\n",
       "      <td>0.344203</td>\n",
       "      <td>0.676143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.413488</td>\n",
       "      <td>0.693815</td>\n",
       "      <td>-0.061657</td>\n",
       "      <td>0.485415</td>\n",
       "      <td>0.650126</td>\n",
       "      <td>-0.094514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383515</td>\n",
       "      <td>0.456094</td>\n",
       "      <td>-0.090617</td>\n",
       "      <td>0.363274</td>\n",
       "      <td>0.524123</td>\n",
       "      <td>-0.091500</td>\n",
       "      <td>0.369089</td>\n",
       "      <td>0.572029</td>\n",
       "      <td>-0.082775</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43133</th>\n",
       "      <td>43132.0</td>\n",
       "      <td>0.596817</td>\n",
       "      <td>0.277752</td>\n",
       "      <td>0</td>\n",
       "      <td>0.678503</td>\n",
       "      <td>0.280885</td>\n",
       "      <td>-0.037339</td>\n",
       "      <td>0.752957</td>\n",
       "      <td>0.232253</td>\n",
       "      <td>-0.043838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671353</td>\n",
       "      <td>0.094854</td>\n",
       "      <td>-0.033591</td>\n",
       "      <td>0.663696</td>\n",
       "      <td>0.140287</td>\n",
       "      <td>-0.042217</td>\n",
       "      <td>0.656522</td>\n",
       "      <td>0.185043</td>\n",
       "      <td>-0.040950</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43134</th>\n",
       "      <td>43133.0</td>\n",
       "      <td>0.262260</td>\n",
       "      <td>0.697358</td>\n",
       "      <td>0</td>\n",
       "      <td>0.394017</td>\n",
       "      <td>0.733313</td>\n",
       "      <td>-0.077223</td>\n",
       "      <td>0.539401</td>\n",
       "      <td>0.660449</td>\n",
       "      <td>-0.112657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324326</td>\n",
       "      <td>0.357174</td>\n",
       "      <td>-0.147188</td>\n",
       "      <td>0.300355</td>\n",
       "      <td>0.459422</td>\n",
       "      <td>-0.137189</td>\n",
       "      <td>0.294677</td>\n",
       "      <td>0.532930</td>\n",
       "      <td>-0.114933</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43135 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2   3         4         5         6   \\\n",
       "0          NaN  0.000000  1.000000   2  3.000000  4.000000  5.000000   \n",
       "1          0.0  0.709993  0.782589   0  0.818884  0.729557 -0.056234   \n",
       "2          1.0  0.338549  0.505901   0  0.439657  0.437370 -0.020094   \n",
       "3          2.0  0.331600  0.650407   0  0.440002  0.610693 -0.018637   \n",
       "4          3.0  0.763677  0.944873   0  0.855445  0.899674 -0.023865   \n",
       "...        ...       ...       ...  ..       ...       ...       ...   \n",
       "43130  43129.0  0.618995  0.709756   0  0.714638  0.767420 -0.089490   \n",
       "43131  43130.0  0.380424  0.777277   0  0.499145  0.807409 -0.031173   \n",
       "43132  43131.0  0.344203  0.676143   0  0.413488  0.693815 -0.061657   \n",
       "43133  43132.0  0.596817  0.277752   0  0.678503  0.280885 -0.037339   \n",
       "43134  43133.0  0.262260  0.697358   0  0.394017  0.733313 -0.077223   \n",
       "\n",
       "             7         8         9   ...         55         56         57  \\\n",
       "0      6.000000  7.000000  8.000000  ...  54.000000  55.000000  56.000000   \n",
       "1      0.896666  0.582237 -0.075635  ...   0.587765   0.510154  -0.120703   \n",
       "2      0.506951  0.327512 -0.032897  ...   0.241660   0.278901  -0.113734   \n",
       "3      0.524808  0.536133 -0.029701  ...   0.285742   0.432299  -0.111022   \n",
       "4      0.913678  0.815270 -0.036524  ...   0.706913   0.725790  -0.079980   \n",
       "...         ...       ...       ...  ...        ...        ...        ...   \n",
       "43130  0.863142  0.729784 -0.122185  ...   0.768363   0.460456  -0.096203   \n",
       "43131  0.633429  0.749210 -0.050144  ...   0.472842   0.503088  -0.120579   \n",
       "43132  0.485415  0.650126 -0.094514  ...   0.383515   0.456094  -0.090617   \n",
       "43133  0.752957  0.232253 -0.043838  ...   0.671353   0.094854  -0.033591   \n",
       "43134  0.539401  0.660449 -0.112657  ...   0.324326   0.357174  -0.147188   \n",
       "\n",
       "              58         59         60         61         62         63  64  \n",
       "0      57.000000  58.000000  59.000000  60.000000  61.000000  62.000000  63  \n",
       "1       0.614871   0.600813  -0.114690   0.633652   0.669997  -0.091255   0  \n",
       "2       0.265261   0.351731  -0.101954   0.284056   0.413315  -0.081208   0  \n",
       "3       0.290253   0.490377  -0.097487   0.295378   0.546413  -0.078214   0  \n",
       "4       0.723299   0.791177  -0.070449   0.724961   0.845564  -0.056686   0  \n",
       "...          ...        ...        ...        ...        ...        ...  ..  \n",
       "43130   0.716564   0.536624  -0.100405   0.681609   0.597335  -0.085523  25  \n",
       "43131   0.472228   0.587706  -0.111767   0.454988   0.660927  -0.095761  25  \n",
       "43132   0.363274   0.524123  -0.091500   0.369089   0.572029  -0.082775  25  \n",
       "43133   0.663696   0.140287  -0.042217   0.656522   0.185043  -0.040950  25  \n",
       "43134   0.300355   0.459422  -0.137189   0.294677   0.532930  -0.114933  25  \n",
       "\n",
       "[43135 rows x 65 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3777441",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "31d5629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1297/1297 [==============================] - 7s 4ms/step - loss: 1.1436 - accuracy: 0.6499\n",
      "Epoch 2/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.4206 - accuracy: 0.8633\n",
      "Epoch 3/100\n",
      "1297/1297 [==============================] - 6s 4ms/step - loss: 0.3115 - accuracy: 0.9029\n",
      "Epoch 4/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.2662 - accuracy: 0.9170: 0s -\n",
      "Epoch 5/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.2366 - accuracy: 0.9257\n",
      "Epoch 6/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.2126 - accuracy: 0.9319\n",
      "Epoch 7/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.2016 - accuracy: 0.9343: 0s - loss: 0.2030 - \n",
      "Epoch 8/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.1831 - accuracy: 0.9405: 2s - loss:\n",
      "Epoch 9/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.1723 - accuracy: 0.9438: 1s - ETA: 0s - loss: 0.1723 - accuracy:  - ETA: 0s - loss: 0.1713 - accu - ETA: 0s - loss: 0.1716 - ac\n",
      "Epoch 10/100\n",
      "1297/1297 [==============================] - 6s 5ms/step - loss: 0.1611 - accuracy: 0.9470: \n",
      "Epoch 11/100\n",
      "1297/1297 [==============================] - 6s 5ms/step - loss: 0.1594 - accuracy: 0.9476\n",
      "Epoch 12/100\n",
      "1297/1297 [==============================] - 6s 4ms/step - loss: 0.1551 - accuracy: 0.9500\n",
      "Epoch 13/100\n",
      "1297/1297 [==============================] - 5s 3ms/step - loss: 0.1420 - accuracy: 0.9536\n",
      "Epoch 14/100\n",
      "1297/1297 [==============================] - ETA: 0s - loss: 0.1424 - accuracy: 0.9533 ETA: 2s - los - ETA: 0s - loss: 0.1426 - accuracy: 0. - 5s 4ms/step - loss: 0.1427 - accuracy: 0.9532\n",
      "Epoch 15/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.1342 - accuracy: 0.9548: 0s - loss:\n",
      "Epoch 16/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.1296 - accuracy: 0.9566: 1s - loss: 0.134 - ETA: 1s - loss: 0.1322 - accuracy: 0.95 - ETA: 1s - loss: 0.1322 - accuracy: 0. - ETA: 0s - loss: 0.1324  - ETA: 0s - loss: 0.1295 \n",
      "Epoch 17/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.1298 - accuracy: 0.9561: 0s - loss: 0.1302 - accu\n",
      "Epoch 18/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.1251 - accuracy: 0.9581: 2s -\n",
      "Epoch 19/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.1203 - accuracy: 0.9599\n",
      "Epoch 20/100\n",
      "1297/1297 [==============================] - 6s 5ms/step - loss: 0.1182 - accuracy: 0.9611: 3s - loss: - ETA: 2s - loss: 0.1231 - ac - ETA: 2s - - ETA: 1s - loss: 0 - ETA: 0s - l - ETA: 0s - loss: 0.1195 - accuracy: \n",
      "Epoch 21/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.1163 - accuracy: 0.9615\n",
      "Epoch 22/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.1170 - accuracy: 0.9616: 0s - loss: 0.1172 - accuracy: 0.\n",
      "Epoch 23/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.1093 - accuracy: 0.9628\n",
      "Epoch 24/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.1085 - accuracy: 0.9649: \n",
      "Epoch 25/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.1105 - accuracy: 0.9631: 1s - loss: 0.1081 - accuracy:  - ETA - ETA: 0s - los\n",
      "Epoch 26/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.1036 - accuracy: 0.9654\n",
      "Epoch 27/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.1043 - accuracy: 0.9655: 0s - loss: 0.1058 - accu\n",
      "Epoch 28/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0998 - accuracy: 0.9672\n",
      "Epoch 29/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0990 - accuracy: 0.9659\n",
      "Epoch 30/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0982 - accuracy: 0.9668: 3s - loss: 0.0995 -  - ETA: 1s - loss: 0.0987 - accura - ETA: 1s - loss: 0.097 - ETA:  - ETA: 0s - loss: 0.0981 - accuracy: 0.96\n",
      "Epoch 31/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0979 - accuracy: 0.9663\n",
      "Epoch 32/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0977 - accuracy: 0.9674\n",
      "Epoch 33/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0905 - accuracy: 0.9700\n",
      "Epoch 34/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.1000 - accuracy: 0.9671\n",
      "Epoch 35/100\n",
      "1297/1297 [==============================] - 6s 4ms/step - loss: 0.0911 - accuracy: 0.9696\n",
      "Epoch 36/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0916 - accuracy: 0.9694\n",
      "Epoch 37/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0914 - accuracy: 0.9684\n",
      "Epoch 38/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0871 - accuracy: 0.9702: 1s - loss: 0.0 - ETA: 0s - loss: 0.0\n",
      "Epoch 39/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0912 - accuracy: 0.9692: 3s - loss: 0.0901 - ac - ETA: 3s - loss: 0.0916 - accuracy - E\n",
      "Epoch 40/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0816 - accuracy: 0.9716: 2s - loss: 0\n",
      "Epoch 41/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0854 - accuracy: 0.9706\n",
      "Epoch 42/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0842 - accuracy: 0.9713\n",
      "Epoch 43/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0844 - accuracy: 0.9711\n",
      "Epoch 44/100\n",
      "1297/1297 [==============================] - 6s 5ms/step - loss: 0.0814 - accuracy: 0.9724: 2s - loss:\n",
      "Epoch 45/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0833 - accuracy: 0.9710: 0s - loss: 0.0834 - accu\n",
      "Epoch 46/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0793 - accuracy: 0.9732\n",
      "Epoch 47/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0787 - accuracy: 0.9731: 3s\n",
      "Epoch 48/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0823 - accuracy: 0.9728: 0s - loss: 0.0824 - accuracy: 0.97\n",
      "Epoch 49/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0758 - accuracy: 0.9738: 0s - loss:\n",
      "Epoch 50/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0793 - accuracy: 0.9741\n",
      "Epoch 51/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0734 - accuracy: 0.9752TA: 7s - loss: 0.0605 - ETA: \n",
      "Epoch 52/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0731 - accuracy: 0.9754\n",
      "Epoch 53/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0768 - accuracy: 0.9739\n",
      "Epoch 54/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0723 - accuracy: 0.9749\n",
      "Epoch 55/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0743 - accuracy: 0.9750: 3s - loss: 0.0 - ETA: 2s - loss: 0.0 - ETA: 0s - loss:\n",
      "Epoch 56/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0704 - accuracy: 0.9758: 0s - loss: 0 - ETA: 0s - loss: 0.0705 - accuracy: 0.\n",
      "Epoch 57/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0774 - accuracy: 0.9743\n",
      "Epoch 58/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0700 - accuracy: 0.9764: 0s - loss: 0\n",
      "Epoch 59/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0700 - accuracy: 0.9761\n",
      "Epoch 60/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0686 - accuracy: 0.9768\n",
      "Epoch 61/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0752 - accuracy: 0.9745\n",
      "Epoch 62/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0672 - accuracy: 0.9774\n",
      "Epoch 63/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0688 - accuracy: 0.9774\n",
      "Epoch 64/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0668 - accuracy: 0.9771\n",
      "Epoch 65/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0700 - accuracy: 0.9767: 1s - loss: 0.0729 - accu - ETA: 1s - loss: 0.072 - ETA: 0s - l\n",
      "Epoch 66/100\n",
      "1297/1297 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.97 - 5s 4ms/step - loss: 0.0655 - accuracy: 0.9776\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0691 - accuracy: 0.9767\n",
      "Epoch 68/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0611 - accuracy: 0.9795: 0s -\n",
      "Epoch 69/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0689 - accuracy: 0.9766\n",
      "Epoch 70/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0664 - accuracy: 0.9783\n",
      "Epoch 71/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0665 - accuracy: 0.9769: 0s - loss: 0.0652 - accuracy:  - ETA: 0s - loss: 0.0647 - accuracy: \n",
      "Epoch 72/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0606 - accuracy: 0.9794\n",
      "Epoch 73/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0637 - accuracy: 0.9789\n",
      "Epoch 74/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0660 - accuracy: 0.9777\n",
      "Epoch 75/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0656 - accuracy: 0.9775\n",
      "Epoch 76/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0652 - accuracy: 0.9782\n",
      "Epoch 77/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0601 - accuracy: 0.9802\n",
      "Epoch 78/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0612 - accuracy: 0.9789: 0s - loss: 0.0614 - accuracy: \n",
      "Epoch 79/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0590 - accuracy: 0.9799: 0s - los\n",
      "Epoch 80/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0564 - accuracy: 0.9806\n",
      "Epoch 81/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0662 - accuracy: 0.9778\n",
      "Epoch 82/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0606 - accuracy: 0.9792\n",
      "Epoch 83/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0573 - accuracy: 0.9805\n",
      "Epoch 84/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0603 - accuracy: 0.9789\n",
      "Epoch 85/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0549 - accuracy: 0.9813\n",
      "Epoch 86/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0624 - accuracy: 0.9781\n",
      "Epoch 87/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0597 - accuracy: 0.9792: 2s - loss: 0 - ETA: 1s - los - ETA\n",
      "Epoch 88/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0535 - accuracy: 0.9822\n",
      "Epoch 89/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0603 - accuracy: 0.9798\n",
      "Epoch 90/100\n",
      "1297/1297 [==============================] - 6s 4ms/step - loss: 0.0615 - accuracy: 0.9800: 0s - loss: 0\n",
      "Epoch 91/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0606 - accuracy: 0.9795\n",
      "Epoch 92/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0567 - accuracy: 0.9809\n",
      "Epoch 93/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0574 - accuracy: 0.9803\n",
      "Epoch 94/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0552 - accuracy: 0.9809\n",
      "Epoch 95/100\n",
      "1297/1297 [==============================] - 5s 3ms/step - loss: 0.0582 - accuracy: 0.9803: 0s - loss: 0.0\n",
      "Epoch 96/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0599 - accuracy: 0.9797: 2s - loss: 0.0\n",
      "Epoch 97/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0547 - accuracy: 0.9820: 0s - loss: 0.0549 - ac\n",
      "Epoch 98/100\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0572 - accuracy: 0.9806\n",
      "Epoch 99/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0591 - accuracy: 0.9806\n",
      "Epoch 100/100\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0555 - accuracy: 0.9814: 0s - loss: 0.0552 - accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1760226e340>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "            Dense(63,  activation='relu'),\n",
    "            Dense(128, activation='relu'),         \n",
    "            #Dense(512, activation='relu'),\n",
    "            Dropout(rate=0.1),\n",
    "            #Dense(512, activation='relu'),\n",
    "            Dropout(rate=0.2),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(26, activation='softmax'),\n",
    "               \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x_train,y_train,epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "24c114b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model_balanced\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model_balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ba9ff9",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca33cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
